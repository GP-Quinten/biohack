{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanscofi.utils import load_dataset\n",
    "from stanscofi.datasets import Dataset\n",
    "from stanscofi.training_testing import cv_training\n",
    "from stanscofi.training_testing import weakly_correlated_split, random_simple_split\n",
    "from stanscofi.validation import compute_metrics, plot_metrics, metrics_list\n",
    "import stanscofi.validation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import benchscofi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 1234\n",
    "decision_threshold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"TRANSCRIPT\"]\n",
    "split_params = {\"metric\": \"cosine\", \"test_size\": 0.2, \"split_randomly\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_params = {\n",
    "    \"PMF\": {\n",
    "        \"reg\": 0.01,\n",
    "        \"learning_rate\": 0.5,\n",
    "        \"n_iters\": 160,\n",
    "        \"n_factors\": 15,\n",
    "        \"batch_size\": 100,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsplits = 5\n",
    "njobs = nsplits - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "dataset_di = load_dataset(\"TRANSCRIPT\", \"../data/\")\n",
    "dataset_di.setdefault(\"same_item_user_features\", {\"dataset_name\": \"TRANSCRIPT\"})\n",
    "dataset_di.setdefault(\"name\", \"TRANSCRIPT\")\n",
    "dataset = Dataset(**dataset_di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'cosine', 'test_size': 0.2, 'split_randomly': True}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not split_params[\"split_randomly\"]:\n",
    "    (train_folds, test_folds), _ = weakly_correlated_split(\n",
    "        dataset,\n",
    "        split_params[\"test_size\"],\n",
    "        early_stop=1,\n",
    "        metric=split_params[\"metric\"],\n",
    "        verbose=True,\n",
    "    )\n",
    "else:\n",
    "    (train_folds, test_folds), _ = random_simple_split(\n",
    "        dataset, split_params[\"test_size\"], metric=split_params[\"metric\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 1., 0.],\n",
       "       [1., 1., 1., ..., 0., 1., 1.],\n",
       "       [1., 0., 0., ..., 1., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 1., 1., 0.],\n",
       "       [1., 0., 0., ..., 1., 1., 1.],\n",
       "       [0., 1., 1., ..., 1., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folds.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.subset(train_folds, subset_name=\"Train_\" + \"TRANSCRIPT\")\n",
    "test_dataset = dataset.subset(test_folds, subset_name=\"Test_\" + \"TRANSCRIPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "* Rating matrix: 613 drugs x 151 diseases\n",
      "Including 180 drugs and 101 diseases involved in at least one positive/negative rating\n",
      "321 positive, 9 negative, 92233 unlabeled (including 18513 unavailable) drug-disease ratings\n",
      "Sparsity: 0.36 percent (on drugs/diseases with at least one known rating 1.82)\n",
      "-----------------------------------\n",
      "* Feature matrices:\n",
      "#Drug features: 12096\tTotal #Drugs: 613\n",
      "Missing features: 0.00 percent\n",
      "#Disease features: 12096\tTotal #Disease: 151\n",
      "Missing features: 0.00 percent\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "* Rating matrix: 613 drugs x 151 diseases\n",
      "Including 63 drugs and 58 diseases involved in at least one positive/negative rating\n",
      "80 positive, 2 negative, 92481 unlabeled (including 74050 unavailable) drug-disease ratings\n",
      "Sparsity: 0.09 percent (on drugs/diseases with at least one known rating 2.24)\n",
      "-----------------------------------\n",
      "* Feature matrices:\n",
      "#Drug features: 12096\tTotal #Drugs: 613\n",
      "Missing features: 0.00 percent\n",
      "#Disease features: 12096\tTotal #Disease: 151\n",
      "Missing features: 0.00 percent\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(613,\n",
       " 151,\n",
       " 63,\n",
       " 58,\n",
       " np.int64(80),\n",
       " np.int64(2),\n",
       " np.int64(92481),\n",
       " np.int64(74050),\n",
       " np.float64(0.08858831282477879),\n",
       " np.float64(2.2441160372194857),\n",
       " 12096,\n",
       " np.float64(0.0),\n",
       " 12096,\n",
       " np.float64(0.0))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.summary()\n",
    "test_dataset.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm\n",
    "__import__(\"benchscofi.\" + algo)\n",
    "model = eval(\"benchscofi.\" + algo + \".\" + algo)(algo_params[algo])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "model.fit(train_dataset, random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################\n",
    "## Cross-validation ##\n",
    "results = cv_training(\n",
    "    eval(\"benchscofi.\" + algo + \".\" + algo),\n",
    "    params,\n",
    "    train_dataset,\n",
    "    threshold=decision_threshold,\n",
    "    metric=\"AUC\",\n",
    "    k=k,\n",
    "    beta=beta,\n",
    "    njobs=njobs,\n",
    "    nsplits=nsplits,\n",
    "    random_state=random_state,\n",
    "    show_plots=False,\n",
    "    verbose=True,\n",
    "    cv_type=\"random\" if (split_params[\"split_randomly\"]) else \"weakly_correlated\",\n",
    ")\n",
    "model = results[\"models\"][np.argmax(results[\"test_metric\"])]\n",
    "\n",
    "#################\n",
    "## Predictions ##\n",
    "#################\n",
    "scores = model.predict_proba(test_dataset)\n",
    "predictions = model.predict(scores, threshold=decision_threshold)\n",
    "\n",
    "model.print_scores(scores)\n",
    "model.print_classification(predictions)\n",
    "\n",
    "#################\n",
    "## Validation  ##\n",
    "#################\n",
    "\n",
    "## disease-wise metrics\n",
    "metrics, plot_args = compute_metrics(\n",
    "    scores, predictions, test_dataset, metrics=metrics_list, k=k, beta=beta, verbose=1\n",
    ")  ## run all metrics\n",
    "plot_args.update({\"model_name\": \"PMF\", \"figsize\": (8, 8)})\n",
    "plot_metrics(**plot_args)\n",
    "\n",
    "## dataset-wide metrics\n",
    "y_test = (test_dataset.folds.toarray() * test_dataset.ratings.toarray()).ravel()\n",
    "y_test[y_test < 1] = 0\n",
    "\n",
    "whole_metrics = [\n",
    "    eval(\"stanscofi.validation.\" + metric)(y_test, scores.toarray().ravel(), k, beta)\n",
    "    for metric in metrics_list\n",
    "    if (metric not in [\"Fscore\", \"TAU\"])\n",
    "]\n",
    "\n",
    "results = pd.concat(\n",
    "    (\n",
    "        pd.DataFrame(\n",
    "            [whole_metrics],\n",
    "            index=[\"Value\"],\n",
    "            columns=[m for m in metrics_list if (m not in [\"Fscore\", \"TAU\"])],\n",
    "        ).T,\n",
    "        metrics,\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
